{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65596eb-c810-40e3-9f00-97d90d41017f",
   "metadata": {},
   "source": [
    "[LangChain の QAGenerationChain によるドキュメントからのQA生成を試す\n",
    "](https://note.com/npaka/n/ncf1dbb190caf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef809ac-3e0e-4177-8a86-43831b0a1d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1278k  100 1278k    0     0  5483k      0 --:--:-- --:--:-- --:--:-- 5464k\n"
     ]
    }
   ],
   "source": [
    "# https://www.nintendo.co.jp/ir/pdf/2023/security_q2303.pdf\n",
    "!curl -o ../data/nintendo.pdf https://www.nintendo.co.jp/ir/pdf/2023/security_q2303.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12015140-adc6-45c2-8e88-7977c746ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"../data/nintendo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e57ec0-ac65-4e65-9b82-0e2ba65118c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96e5369-ef18-4d35-bba7-543157476918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Base: https://aoai-r7a5whblfnou2.openai.azure.com/\n",
      "OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "OPENAI_MODEL_NAME = \"gpt-35-turbo\"\n",
    "OPENAI_DEPLOYMENT_ID = \"chat\"\n",
    "OPENAI_API_TYPE = \"azure\"\n",
    "OPENAI_API_VERSION = \"2023-09-01-preview\"\n",
    "\n",
    "# \"https://<your-endpoint.openai.azure.com/\"\n",
    "OPENAI_API_BASE = input('OpenAI API Base:')\n",
    "OPENAI_API_KEY = getpass.getpass('OpenAI API Key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f8190cd-13cf-4fef-afbc-cbd91d7fd879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat model\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=OPENAI_MODEL_NAME,\n",
    "    openai_api_base=OPENAI_API_BASE,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    temperature=0,\n",
    "    model_kwargs={\n",
    "        \"deployment_id\": OPENAI_DEPLOYMENT_ID,\n",
    "        \"api_type\": OPENAI_API_TYPE,\n",
    "        \"api_version\": OPENAI_API_VERSION,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed2d064-187f-4791-8747-281a698a4e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QAGenerationChain(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['text'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a smart assistant designed to help high school teachers come up with reading comprehension questions.\\nGiven a piece of text, you must come up with a question and answer pair that can be used to test a student\\'s reading comprehension abilities.\\nWhen coming up with this question/answer pair, you must respond in the following format:\\n```\\n{{\\n    \"question\": \"$YOUR_QUESTION_HERE\",\\n    \"answer\": \"$THE_ANSWER_HERE\"\\n}}\\n```\\n\\nEverything between the ``` must be valid json.\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='Please come up with a question/answer pair, in the specified JSON format, for the following text:\\n----------------\\n{text}'))]), llm=ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-35-turbo', temperature=0.0, model_kwargs={'deployment_id': 'chat', 'api_type': 'azure', 'api_version': '2023-09-01-preview'}, openai_api_key='1fc38e223ec44a0f9125bdbee370adef', openai_api_base='https://aoai-r7a5whblfnou2.openai.azure.com/', openai_organization='', openai_proxy='')), text_splitter=<langchain.text_splitter.RecursiveCharacterTextSplitter object at 0x7f8fa42e1150>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import QAGenerationChain\n",
    "\n",
    "chain = QAGenerationChain.from_llm(\n",
    "    llm=llm,\n",
    ")\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eed0826-1124-48eb-be89-b88d44fc7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_message = 'You are a smart assistant designed to help high school teachers come up with reading comprehension questions.\\nGiven a piece of text, you must come up with a question and answer pair that can be used to test a student\\'s reading comprehension abilities.\\nWhen coming up with this question/answer pair, you must respond in the following format:\\n```\\n{{\\n    \"question\": \"$YOUR_QUESTION_HERE\",\\n    \"answer\": \"$THE_ANSWER_HERE\"\\n}}\\n```\\n\\nEverything between the ``` must be valid json.\\n'\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=[],\n",
    "            template=system_message + 'answer in Japanese',\n",
    "        )\n",
    "    ),\n",
    "    HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=['text'],\n",
    "            template='Please come up with a question/answer pair, in the specified JSON format, for the following text:\\n----------------\\n{text}',\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "chain = QAGenerationChain.from_llm(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd095ae-9b61-4bea-9ad6-14844f06c80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'この文書は何の目的で提出されましたか？', 'answer': '有価証券報告書を提出するため'}]\n",
      "[{'question': '2023年3月の売上高はいくらですか？', 'answer': '1,601,677百万円'}]\n",
      "[{'question': '2023年3月の売上高は何百万円ですか？', 'answer': '1,409,503'}]\n",
      "[{'question': '任天堂はいつ株式会社丸福として発足しましたか？', 'answer': '1947年11月'}]\n",
      "[{'question': '当社及び関係会社が事業として行っている主な活動は何ですか？', 'answer': 'ホームエンターテインメントの分野で娯楽製品の開発、製造及び販売等を事業としています。'}]\n",
      "[{'question': '事業系統図は何を示すために使用されますか？', 'answer': '事業系統図は前述の事項を示すために使用されます。'}]\n",
      "[{'question': '任天堂の関係会社の中で、最も多くの従業員を抱えているのはどこですか？', 'answer': 'NintendoofAmericaInc.'}]\n",
      "[{'question': '上記のテキストによれば、連結子会社の数はいくつですか？', 'answer': '5社'}]\n",
      "[{'question': '提出会社の従業員数は何人ですか？', 'answer': '2,779人'}]\n",
      "[{'question': '当社グループの経営方針は何ですか？', 'answer': '当社グループの経営方針は、「娯楽を通じて人々を笑顔にする会社」として、健全な企業経営を維持しつつ新しい娯楽の創造を目指すことです。'}]\n"
     ]
    }
   ],
   "source": [
    "count_max = 10\n",
    "count = 0\n",
    "for document in documents:\n",
    "    print(chain.run(document.page_content))\n",
    "    count = count + 1\n",
    "    if count >= count_max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80644d5-e0dd-456b-92d2-4ca6803b5e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
