{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ab82fb-0231-4877-9ae5-f17e7b083b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Base: https://aoai-r7a5whblfnou2.openai.azure.com/\n",
      "OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/integrations/text_embedding/azureopenai\n",
    "# https://python.langchain.com/docs/modules/data_connection/vectorstores.html?highlight=chroma#langchain.vectorstores.Chroma\n",
    "# set the environment variables needed for openai package to know to reach out to azure\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "OPENAI_API_TYPE = \"azure\"\n",
    "OPENAI_API_VERSION = \"2023-05-15\"\n",
    "\n",
    "# \"https://<your-endpoint.openai.azure.com/\"\n",
    "OPENAI_API_BASE = input('OpenAI API Base:')\n",
    "OPENAI_API_KEY = getpass.getpass('OpenAI API Key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fecf091-d41b-4bdd-a94c-7744db39cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/modules/data_connection/vectorstores.html?highlight=chroma#langchain.vectorstores.Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "# https://github.com/langchain-ai/langchain/blob/c732d8fffd39d2b02bdc393c37d2ccdd48f7626d/docs/extras/modules/state_of_the_union.txt\n",
    "raw_documents = TextLoader('./test.txt').load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b78d2c3-2bc8-4922-9276-64bdc5685ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory=\"../data\"\n",
    "db_collection_name=\"chroma\"\n",
    "\n",
    "def get_chroma_db():\n",
    "    return Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=OpenAIEmbeddings(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            deployment=\"embedding\",\n",
    "            openai_api_version=OPENAI_API_VERSION,\n",
    "            openai_api_base=OPENAI_API_BASE,\n",
    "            openai_api_type=OPENAI_API_TYPE,\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "        ),\n",
    "        collection_name=db_collection_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80fe45f-f06a-4190-bfe8-a61b0c4cbb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete embedding: 1 / 42\n",
      "complete embedding: 2 / 42\n",
      "complete embedding: 3 / 42\n",
      "complete embedding: 4 / 42\n",
      "complete embedding: 5 / 42\n",
      "complete embedding: 6 / 42\n",
      "complete embedding: 7 / 42\n",
      "complete embedding: 8 / 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete embedding: 9 / 42\n",
      "complete embedding: 10 / 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete embedding: 11 / 42\n",
      "complete embedding: 12 / 42\n",
      "complete embedding: 13 / 42\n",
      "complete embedding: 14 / 42\n",
      "complete embedding: 15 / 42\n",
      "complete embedding: 16 / 42\n",
      "complete embedding: 17 / 42\n",
      "complete embedding: 18 / 42\n",
      "complete embedding: 19 / 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete embedding: 20 / 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete embedding: 21 / 42\n",
      "complete embedding: 22 / 42\n",
      "complete embedding: 23 / 42\n",
      "complete embedding: 24 / 42\n",
      "complete embedding: 25 / 42\n",
      "complete embedding: 26 / 42\n",
      "complete embedding: 27 / 42\n",
      "complete embedding: 28 / 42\n",
      "complete embedding: 29 / 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete embedding: 30 / 42\n",
      "complete embedding: 31 / 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete embedding: 32 / 42\n",
      "complete embedding: 33 / 42\n",
      "complete embedding: 34 / 42\n",
      "complete embedding: 35 / 42\n",
      "complete embedding: 36 / 42\n",
      "complete embedding: 37 / 42\n",
      "complete embedding: 38 / 42\n",
      "complete embedding: 39 / 42\n",
      "complete embedding: 40 / 42\n",
      "complete embedding: 41 / 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete embedding: 42 / 42\n"
     ]
    }
   ],
   "source": [
    "# Create index\n",
    "db = get_chroma_db()\n",
    "\n",
    "for idx, doc in enumerate(documents):\n",
    "    db.add_documents([doc])\n",
    "    print(f\"complete embedding: {idx+1} / {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e80b7a-653a-469f-9bc8-b1793f104026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And so many families are living paycheck to paycheck, struggling to keep up with the rising cost of food, gas, housing, and so much more. \\n\\nI understand. \\n\\nI remember when my Dad had to leave our home in Scranton, Pennsylvania to find work. I grew up in a family where if the price of food went up, you felt it. \\n\\nThat’s why one of the first things I did as President was fight to pass the American Rescue Plan.  \\n\\nBecause people were hurting. We needed to act, and we did. \\n\\nFew pieces of legislation have done more in a critical moment in our history to lift us out of crisis. \\n\\nIt fueled our efforts to vaccinate the nation and combat COVID-19. It delivered immediate economic relief for tens of millions of Americans.  \\n\\nHelped put food on their table, keep a roof over their heads, and cut the cost of health insurance. \\n\\nAnd as my Dad used to say, it gave people a little breathing room.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load from disk\n",
    "db2 = get_chroma_db()\n",
    "\n",
    "query = \"It fueled our efforts to vaccinate the nation and combat COVID-19. It delivered immediate economic relief for tens of millions of Americans.\"\n",
    "docs = db2.similarity_search(query)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c18cb0-f765-4b40-9af0-9ce5b7246cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db2.similarity_search_with_relevance_scores(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "237be27b-1264-4998-b6e8-c20fa7a4c543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066367575096858"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6a1d9-04e6-47ea-9afb-15b1db832e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
